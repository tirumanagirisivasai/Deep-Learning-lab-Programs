{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9pPqDIm5mGjwrEMZXwagl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirumanagirisivasai/Deep-Learning-lab-Programs/blob/main/Experiment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7QPld48zQrm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # Initialize weights and biases\n",
        "        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size)\n",
        "        self.bias_input_hidden = np.random.randn(1, self.hidden_size)\n",
        "        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size)\n",
        "        self.bias_hidden_output = np.random.randn(1, self.output_size)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.hidden_input = np.dot(inputs, self.weights_input_hidden) + self.bias_input_hidden\n",
        "        self.hidden_output = self.sigmoid(self.hidden_input)\n",
        "        self.output = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_hidden_output\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, inputs, targets, learning_rate):\n",
        "        # Compute output layer error\n",
        "        output_error = targets - self.output\n",
        "        output_delta = output_error\n",
        "\n",
        "        # Compute hidden layer error\n",
        "        hidden_error = output_delta.dot(self.weights_hidden_output.T)\n",
        "        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "        # Update weights and biases\n",
        "        self.weights_hidden_output += self.hidden_output.T.dot(output_delta) * learning_rate\n",
        "        self.bias_hidden_output += np.sum(output_delta, axis=0, keepdims=True) * learning_rate\n",
        "        self.weights_input_hidden += inputs.T.dot(hidden_delta) * learning_rate\n",
        "        self.bias_input_hidden += np.sum(hidden_delta, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "\n",
        "    def train(self, inputs, targets, epochs, learning_rate):\n",
        "        for epoch in range(epochs):\n",
        "            output = self.forward(inputs)\n",
        "            self.backward(inputs, targets, learning_rate)\n",
        "            loss = np.mean(np.square(targets - output))\n",
        "            if epoch % 1000 == 0:\n",
        "                print(f'Epoch {epoch}: Loss {loss} Output:{output}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define training data\n",
        "    X = np.array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])  # Input\n",
        "    y = np.array([[0], [1], [1], [0]])              # Target\n",
        "\n",
        "    # Define neural network\n",
        "    input_size = 3\n",
        "    hidden_size = 4\n",
        "    output_size = 1\n",
        "    neural_net = NeuralNetwork(input_size, hidden_size, output_size)\n",
        "\n",
        "    # Train neural network\n",
        "    neural_net.train(X, y, epochs=10000, learning_rate=0.01)\n",
        "\n",
        "    # Test the trained network\n",
        "    print(\"Output after training:\")\n",
        "    outputs = neural_net.forward(X)\n",
        "    for i in outputs:\n",
        "      if i[0]>=0.5:\n",
        "        print(1.0)\n",
        "      else:\n",
        "        print(0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkQFFrMXztry",
        "outputId": "4beb1d41-9ed6-4af0-870f-e0e1f14691cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss 13.180076780887763 Output:[[-2.65885526]\n",
            " [-3.4130427 ]\n",
            " [-3.4836542 ]\n",
            " [-2.46428385]]\n",
            "Epoch 1000: Loss 0.00034256858580434505 Output:[[0.00407124]\n",
            " [0.98227197]\n",
            " [0.98094587]\n",
            " [0.02600685]]\n",
            "Epoch 2000: Loss 1.6038644427808318e-05 Output:[[-0.00319344]\n",
            " [ 0.99524826]\n",
            " [ 1.00427575]\n",
            " [ 0.00361877]]\n",
            "Epoch 3000: Loss 1.5617422762636303e-05 Output:[[-0.00310179]\n",
            " [ 0.9953663 ]\n",
            " [ 1.00461832]\n",
            " [ 0.00316994]]\n",
            "Epoch 4000: Loss 1.5292207580165986e-05 Output:[[-0.00306004]\n",
            " [ 0.99540981]\n",
            " [ 1.00457947]\n",
            " [ 0.00312468]]\n",
            "Epoch 5000: Loss 1.4975650696721423e-05 Output:[[-0.00302646]\n",
            " [ 0.99545633]\n",
            " [ 1.004533  ]\n",
            " [ 0.00309033]]\n",
            "Epoch 6000: Loss 1.4667383614550541e-05 Output:[[-0.00299387]\n",
            " [ 0.99550239]\n",
            " [ 1.00448699]\n",
            " [ 0.00305691]]\n",
            "Epoch 7000: Loss 1.436712340424976e-05 Output:[[-0.00296184]\n",
            " [ 0.99554776]\n",
            " [ 1.00444168]\n",
            " [ 0.00302407]]\n",
            "Epoch 8000: Loss 1.407459947604455e-05 Output:[[-0.00293034]\n",
            " [ 0.99559243]\n",
            " [ 1.00439706]\n",
            " [ 0.00299178]]\n",
            "Epoch 9000: Loss 1.3789552821397957e-05 Output:[[-0.00289935]\n",
            " [ 0.99563644]\n",
            " [ 1.00435312]\n",
            " [ 0.00296001]]\n",
            "Output after training:\n",
            "0.0\n",
            "1.0\n",
            "1.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = neural_net.weights_input_hidden\n",
        "count = 0\n",
        "for i in weights:\n",
        "  print(f'Weights of the neuron {count+1} in hidden layer are = {i}')\n",
        "  count+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG0Rwt0O15kf",
        "outputId": "fecdcdea-1983-41a5-b4c6-4b51acf21c6b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights of the neuron 1 in hidden layer are = [-1.98777568  1.04378926 -1.62555225 -0.47930664]\n",
            "Weights of the neuron 2 in hidden layer are = [-0.70243984  0.09229976  0.03752961  0.0735066 ]\n",
            "Weights of the neuron 3 in hidden layer are = [-0.40040643 -1.74432702 -0.53685019 -0.5301744 ]\n"
          ]
        }
      ]
    }
  ]
}